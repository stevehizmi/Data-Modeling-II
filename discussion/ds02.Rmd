---
title:  "STAT340: Discussion 2: Data \"Playgrounds\""
author: Steven Hizmi, Levi Cameron
date:   "`r format(Sys.time(), '%d %B, %Y')`" # autogenerate date as date of last knit
documentclass: article
classoption: letterpaper
output:
  html_document:
  highlight: tango
---

```{r setup, include=FALSE}
# if sourced, set working directory to file location
if(Sys.getenv('RSTUDIO')=='1') setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

# install necessary packages
if(!require(pacman)) install.packages("pacman")
pacman::p_load(knitr)

knitr::opts_chunk$set(tidy=FALSE,strip.white=FALSE,fig.align="center",comment=" #")
```

---

## Synthesizing data using "playgrounds"

### Background

The goal of today's discussion is to get you thinking about **ways of synthesizing data** from multiple sources to create a data frame that gives a more complete picture of the world and is more interesting and productive to study.

One of the easiest ways of doing this is by using what Karl calls __*data playgrounds*__; these are usually some kind of unique identifier that can be used to connect two disjoint data sets. Examples include [FIPS county codes](https://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/home/?cid=nrcs143_013697), [NPI numbers](https://npidb.org/npi-lookup/), postal codes, etc.

Using the latest figures from [USA Facts](https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/), we have prepared a dataset of [**daily covid-19 cases and deaths**](https://github.com/karlrohe/340-Spring21/blob/master/data/covid/covid19.csv.gz) ([direct download link](https://github.com/karlrohe/340-Spring21/raw/master/data/covid/covid19.csv.gz)) for **each county in the US** (.csv.gz means it's a gzip compressed csv file (to save space), which R can read directly like any other csv file using standard `read.csv` or `read_csv` from the tidyverse package). The data frame includes the date, names and FIPS codes for each state and county, population, and confirmed cases & deaths.

```{r, message=F,warning=F,cache=T}
# install package manager (if not installed) for convenience, then load tidyverse
if(!require(pacman)) install.packages("pacman")
pacman::p_load(tidyverse)

# change this path to wherever you downloaded the dataset
# col_types used to force FIPS codes to read as characters (to preserve leading 0's)
# read for more info: https://readr.tidyverse.org/reference/read_delim.html
covid19 = read_csv("covid19.csv.gz",col_types="Dcccciii")

# inspect the data frame
head(covid19)
tail(covid19)

covid19
```

```{r}
madisonCases = covid19 %>% filter(countyName == "Dane County")
baldwinCases = covid19 %>% filter(countyName == "Baldwin County", stateName == "AL")

madisonCases
baldwinCases
```

Things to note:

 - These are **only the confirmed counts** (actual counts likely to be much higher in most counties).
 - Some rows denote **unallocated cases** and may need special treatment.
 - The **state FIPS code** forms the **first two digits of the county FIPS code** (e.g. Wyoming (WY) has state FIPS code 56, so every county in WY has a FIPS code starting with "56...").
 - In some datasets, the **county FIPS code may not include the state FIPS code**, which may be in a separate column (e.g. Teton County (WY) may have FIPS code listed as just "039" instead of "56039").


### Exercise

Your task is to **merge the covid-19 data** with a second dataset to give it a new and unique perspective, **using the FIPS codes**. To save time, Karl has written a script to provide you with monthly county statistics from the Bureau of Labor Statistics (BLS) over a period of about a year, including estimates of the labor force, number of employed vs unemployment, and employment rate. Use this as your second dataset.

```{r,cache=T}
# run Karl's script
source("https://raw.githubusercontent.com/karlrohe/340-Spring21/master/data/bls/recent_county_months.R")

# run Karl's function to get BLS county data
bls_county = get_bls_county()

# inspect the data frame
str(bls_county)
head(bls_county)
tail(bls_county)
```


Note this dataset covers **a different period of time** than the covid-19 dataset, so you will probably need to either take a subset of a single point in time, or use some kind of summarization/aggregation to make the two datasets **compatible before joining them**. You should **use your best judgment** as aspiring data scientists to determine what method both makes sense and is also interesting.

After joining them, **make at least 1 _interesting_ plot** visualizing the data in **some way that was not possible before merging** the two datasets.
```{r}
baldwinCases <- covid19[covid19$date %in% seq(as.Date("2020-02-01"), as.Date("2020-11-01"), by="month"),] %>% 

 filter(countyName == "Baldwin County")

madisonCases <- covid19[covid19$date %in% seq(as.Date("2020-02-01"), as.Date("2020-11-01"), by="month"),] %>% 

 filter(countyName == "Dane County")

madison <- bls_county[bls_county$period %in% seq(as.Date("2020-02-01"), as.Date("2021-01-01"), by="month"),] %>% 

 filter(area_title == "Dane County, WI") %>% rename(date = period)



baldwin <- bls_county[bls_county$period %in% seq(as.Date("2020-02-01"), as.Date("2021-01-01"), by="month"),] %>% 

 filter(area_title == "Baldwin County, AL") %>% rename(date = period)

madison 
baldwin
baldwinCases
madisonCases

inner_join(madison, madisonCases)

```

## Submission

Make sure the **names of everyone** who worked on this with you is included in the header of this document. Then, **knit this document** and submit **both this file and the HTML output** on Canvas under Assignments â‡’ Discussion 2.
